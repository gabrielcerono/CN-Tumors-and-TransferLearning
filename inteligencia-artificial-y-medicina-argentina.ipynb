{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport os\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom keras.utils.np_utils import to_categorical \nfrom keras.models import Sequential, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import EarlyStopping\nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras import Model,layers\nfrom sklearn.metrics import classification_report,confusion_matrix\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](https://www.mayoclinic.org/-/media/kcms/gbs/patient-consumer/images/2014/10/30/15/17/mcdc7_brain_cancer-8col.jpg)","attachments":{}},{"metadata":{},"cell_type":"markdown","source":"# Utilizacion de Inteligencia Artificial para el reconocimiento de tumores cerebrales"},{"metadata":{},"cell_type":"markdown","source":"Los tumores de cerebro son generalmente evaluados inicialmente mediante Resonancia Magnetica, y confirmados posteriormente con biopsia. A continuacion tratare de crear un prototipo de Modelo de Inteligencia Artificial, para poder clasificar diferentes tipos de tumores adecuadamente. Los datos que utilizo son de Kaggle, y estan conformados por multiples Resonancias Magneticas en T1 y T2, esta misma tiene 4 categorias. Las categorias estan conformadas por gliomas, meningiomas, tumores de hipofisis, y cerebros sin patologias. \n\nEn una primera parte utilizare una Red Neuronal Convolucional tipica para el modelo, en una segunda etapa voy a utilizar una tecnica que se esta popularizando, llamada TransferLearning. Una de las grandes limitaciones de la inteligencia artificial es el dificil acceso a una base de datos en buenas condiciones estructurales. La utilizacion de redes neuronales \"pre-entrenadas\", puede sortear este obstaculo y generalmente suele producir mejores resultados sobre todo en datasets de baja calidad o de baja cuantia. "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = \"/kaggle/input/brain-tumor-classification-mri/Training/\"\ntest_path=\"/kaggle/input/brain-tumor-classification-mri/Testing/\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checkeamos que tenemos bien las direcciones de nuestras Imagenes. "},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(test_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir(train_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Miremos algunas de las Resonancias Magneticas**\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Adenoma de hipofisis"},{"metadata":{"trusted":true},"cell_type":"code","source":"para_cell = \"../input/brain-tumor-classification-mri/Training/pituitary_tumor/p (102).jpg\"\npara_img= imread(para_cell)\nplt.imshow(para_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Un Glioma"},{"metadata":{"trusted":true},"cell_type":"code","source":"para_cell1 = \"../input/brain-tumor-classification-mri/Training/glioma_tumor/gg (112).jpg\"\npara_img= imread(para_cell1)\nplt.imshow(para_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Una Resonancia sin patologia"},{"metadata":{"trusted":true},"cell_type":"code","source":"para_cell2 = \"../input/brain-tumor-classification-mri/Training/no_tumor/image (21).jpg\"\npara_img= imread(para_cell2)\nplt.imshow(para_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Un Meningioma"},{"metadata":{"trusted":true},"cell_type":"code","source":"para_cell3 = \"../input/brain-tumor-classification-mri/Training/meningioma_tumor/m (125).jpg\"\npara_img= imread(para_cell3)\nplt.imshow(para_img)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Hacemos un pre-procesamiento de las imagenes, y producimos artificialmente un aumento en el volumen de imagenes de entrenamiento, como resultado esto nos prosporcionara un modelo mas robusto.[](http://)"},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen = ImageDataGenerator( ImageDataGenerator(\n        featurewise_center=False,  \n        samplewise_center=False, \n        rescale=1. / 255,\n        zca_whitening=False,  \n        rotation_range=0.9,\n        zoom_range = 0.9,\n        width_shift_range=0,  \n        height_shift_range=0,  \n        horizontal_flip=True,  \n        vertical_flip=False)  \n                              )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_shape = (224,224,3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen.flow_from_directory(train_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_gen.flow_from_directory(test_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Programamos una Red Neuronal Convolucional. "},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\n\nmodel.add(Conv2D(filters = 64, kernel_size = (5,5),padding = 'Same', activation ='relu', input_shape = (224,224,3)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (3,3),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters = 128, kernel_size = (2,2),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\n\nmodel.add(Conv2D(filters = 256, kernel_size = (2,2),padding = 'Same', activation ='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(1024, activation = \"relu\"))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(4, activation = \"softmax\"))\n\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n\nmodel.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_gen = image_gen.flow_from_directory(train_path,\n                                               target_size=image_shape[:2],\n                                                color_mode='rgb',\n                                               batch_size=batch_size,\n                                               class_mode='categorical')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_gen = image_gen.flow_from_directory(test_path,\n                                               target_size=image_shape[:2],\n                                               color_mode='rgb',\n                                               batch_size=batch_size,\n                                               class_mode='categorical',shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"early_stop = EarlyStopping(monitor='val_loss',patience=2)"},{"metadata":{"trusted":true},"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss',patience=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_image_gen,epochs=20,\n                              validation_data=test_image_gen,\n                              callbacks=[early_stop])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluemos que tambien le ha ido a nuestro modelo."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history[\"accuracy\"],c = \"red\")\nplt.plot(history.history[\"val_accuracy\"],c = \"black\")\nplt.title(\"Loss\")\nplt.ylabel(\"Loss\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"train\", \"test\"])\nplt.rcParams[\"figure.figsize\"] = (6,6)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(test_image_gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Como podemos ver, el modelo tiene un 64% de Accuracy. Con 4 categorias (Con el mismo numero dei magenes en cada una), si eligieramos al azar tendriamos un 25% chances de acertar. Esto es bueno pero no lo suficiente. "},{"metadata":{},"cell_type":"markdown","source":"# Podemos guardar nuestro modelo en un simple archivo, y utilizarlo luego facilmente para clasificar tumores."},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"model_brainTumor.h5\")\nclassifier = load_model('model_brainTumor.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Como pudimos ver, la red neuronal tal vez no funciono tan bien como hubiesemos querido. Utilizaremos otra tecnica para ver si podemos mejorar los resultados. "},{"metadata":{},"cell_type":"markdown","source":"> # TransferLearning"},{"metadata":{},"cell_type":"markdown","source":"TransferLearning, es una tecnica en la cual tomamos redes neuronales \"pre-entrenadas\" y las utilizamos en nuestro propio DataSet, en este caso, en las resonancias magneticas de tumores cerebrales. La tecnica consiste solamente en tomar las capas inferiores de la misma, que sirven para el reconocimiento de patrones generales, como linea y curvas, mientras que retiramos la capa de neuronas mas superficiales y que detectan patrones mas especificos, y lo reemplazamos por capas programadas por nosotros mismos. Esto reduce bastante el tiempo de entrenamiento y generalmente mejora el valor predictivo del modelo. "},{"metadata":{},"cell_type":"markdown","source":"# Resnet50"},{"metadata":{},"cell_type":"markdown","source":"Resnet50 es una arquitectura de Redes Convolucionales, con una estructura Residual, inspirada en las Celulas Piramidales de la corteza cerebral. Esta arquitectura utiliza conexiones en salto, es decir, ciertas nueronas no conectan con la capa siguiente, como lo harian en un modelo convencional sino que saltan 2 o 3 capas mas adelante. Este tipo de arquitectura le proporciona al modelo la capacidad de apilar un gran numeros de capas neuronales sin correr riesgo del famoso \"Vanishing Gradients\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import ResNet50\n\npretrained_model=ResNet50( input_shape=(224,224,3),\n                                  include_top=False,\n                                  weights='imagenet'\n                                   )\n\nfor layer in pretrained_model.layers:\n     layer.trainable = False\n\npretrained_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"last_layer = pretrained_model.get_layer('conv5_block3_out')\nprint('last layer of rsnet50 : output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nx = layers.Flatten()(last_output)\nx = layers.Dense(1024, activation='relu')(x)\nx = layers.Dropout(0.2)(x)                  \nx = layers.Dense(4, activation='softmax')(x)\n\nmodel_resnet = Model(pretrained_model.input, x) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_resnet.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'categorical_crossentropy', \n              metrics = ['acc'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_resnet.fit_generator(train_image_gen,epochs=20,\n                              validation_data=test_image_gen,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history[\"acc\"],c = \"green\")\nplt.plot(history.history[\"val_acc\"],c = \"blue\")\nplt.axis([0, 20, 0, 1])\nplt.title(\"Accuracy\")\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.legend([\"train\", \"test\"])\nplt.rcParams[\"figure.figsize\"] = (10,10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_resnet.evaluate_generator(test_image_gen)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Como podemos ver, nuestro nuevo modelo tiene unas chances del casi 80% de predecir correctamente un tumor de craneo. Bastante superior al 64% del Modelo anterior, incluso con menor tiempo de entrenamiento. Esto podria demostrar a priori la superioridad del TransferLearning.**"},{"metadata":{},"cell_type":"markdown","source":"# Limitaciones"},{"metadata":{},"cell_type":"markdown","source":"> Como pudimos ver, con unas simples lineas de codigo podemos brindar una elegante solucion a lo que podria ser una posible falta de personal especializado en reconocimiento de imagenes. Aunque un 80% de certeza, no es aceptable en el ambito medico, con un mayor numero de imagenes y de mayor caldiad podriamos aumentar la certeza del modelo.\nEsto no reemplazaria el rol del profesional especializado pero podria ser una herramienta util en el workflow, o para proporcionar conocimientos tecnico en areas rurales o sin acceso a este tipo de profesionales. \n\n"},{"metadata":{},"cell_type":"markdown","source":"Autor: Gabriel Cerono"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}